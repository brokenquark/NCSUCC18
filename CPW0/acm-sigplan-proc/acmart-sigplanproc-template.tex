\documentclass[sigplan, review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

\acmConference[NCSU, FALL 2018]{CSC512 - Compiler Construction}{October 18, 2018}{Raleigh, NC, USA}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\setcopyright{none}


\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption


\begin{document}

%% Title information
\title[Course Project Writeup - 0]{Course Project Writeup - 0}         
\subtitle{SPARK API Converter}                    


\author{Md Rayhanur Rahman}
\authornote{unity id: 200255928}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Ph.D. Student}
  \department{Dept. of CSC}              %% \department is recommended
  \institution{NC State University}            %% \institution is required
  \city{Raleigh}
  \state{NC}
  \country{USA}                   %% \country is recommended
}
\email{mrahman@ncsu.edu}          %% \email is recommended

\author{Mohammad Maruful Haque}
\authornote{unity id: 200262103}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
	\position{Ph.D. Student}
	\department{Dept. of CSC}              %% \department is recommended
	\institution{NC State University}            %% \institution is required
	\city{Raleigh}
	\state{NC}
	\country{USA}                    %% \country is recommended
}
\email{mhaque3@ncsu.edu}          %% \email is recommended


\begin{abstract}
This report contains the initial concept notes from the SCALA API Converter programming project describing the problem definition, background, related work, methodology, timeline, testing criteria and finally workload distribution.
\end{abstract}

\maketitle


\section{The Problem}
In this project, we need to build a source code converter which can transform these following things along with some additional tasks. 
\begin{enumerate}
	\item \textbf{RQ1:} Getting introduced with Apache Spark, setting it up in a docker container and writing some piece of code in Spark RDD, Dataset and Dataframe API
	\item \textbf{RQ2:} Spark RDD API to Spark Dataset API
	\item \textbf{RQ3:} Spark RDD API to Spark Dataframe API
	\item \textbf{RQ4:} Implementing some Spark SQL Api calls to Scala functions
\end{enumerate}

\section{Background and Motivation}
Spark is very popular these days for distributed computing tasks such as data analysis, graph modeling and machine learning etc. There are three APIs in Spark at present named RDD, Dataset and Dataframe. The three different APIs provide different expressive power to achieve the same thing although the performance gain can be different. Moreover, Spark introduced these three APIs in different times so that there are many existing implementations of Spark based systems that needs to be rewritten to gain better performance. So, an API transformer can be handy to migrate Spark APIs to achieve better performance. Moreover, by doing this, a great understanding will be built on compiler techniques such as scanning and parsing, handling CFG grammar and intermediate representation.  

\section{Related Work}
To the best of our knowledge after performing an exhaustive search, there is no automatic transformer for this problem. Although there are some good practices and tutorials on how to convert RDD API code to Dataset and Dataframe API, but those have to be done by a programmer and is a manual, time consuming process. 

\section{Methodology}
RQ1 and RQ4 are pretty straightforward. All that is needed to be performed is to install docker in the system, deploy the spark image there and then playing with the spark API to learn how to use it. But RQ2 and RQ3 is a sizable task. Here is the abstract thoughts on how to solve these two problems. 

\begin{enumerate}
	\item \textbf{RQ2:} It should not be that much challanging. A tokenizer needs to be developed that can extract all the tokens from a RDD API code sequence. Then, using the RDD to Dataframe transformation rule, the RDD tokens need to be replace with the corresponding Dataframe tokens.
	\item \textbf{RQ3:} It is not that straightforward as the previous task. Apart from the tokenizer, a parser needs to developed that can build an AST of the RDD API. For parsing, the provided grammar needs to be also converted to a LL1 or LR1 as the provided grammar is ambiguous. After building the AST, UDF part from the RDD API needs to be extracted and replaced with the SQL API. But this is challenging because a custom set of SQL rules and grammars need to be developed to replace UDF tokens with SQL. tokens. Basically, a lambda expression needs to be converted to a declarative SQL expression to achieve the goal. 
\end{enumerate}  

\section{Testing Criteria}
The transformer program should be standalone and self packaged. Hence, there should be no need for configuration or settings file. It will be designed in such a way so that the tester can test it just by running the scripts and providing appropriate input files. Custom test cases can be written as well to test some sample inputs and outputs. The programming language that is preferred to be used is either Java or Python with ANTLR4 for handling the grammar. However, the whole scanner and parser can also be written from scratch. The code samples as input and produced output code samples must preserve the same meaning and produce the same result. That should be the key testing criteria. 

\section{Workload Distribution}
These are the breakdown of the whole project work:
\begin{enumerate}
	\item Setting up Spark and writing programs in three different API - Maruful
	\item Building a Scanner for RDD - Rayhanur
	\item Replacing RDD tokens with Dataset tokens - Rayhanur
	\item Building a Parser for RDD - Rayhanur
	\item Building an AST generator for RDD - Rayhanur
	\item Converting the provided grammar to LL1 or LR1 - Rayhanur
	\item Developing custom rules for Spark SQL - Maruful
	\item Converting RDD UDF to Spark SQL - Maruful
	\item Writing Scala functions for several Spark SQL Api - Maruful
\end{enumerate}

\section{Timeline}
\begin{enumerate}
	\item Part 1 \& 2 is expected to be finished by November 1
	\item Part 3 is expected to be finished by November 28
	\item Other miscellaneous task such as report writing, test cases, packaging are expected to be finished by December 1
\end{enumerate}






%% Bibliography
%\bibliography{bibfile}
%\bibliographystyle{ACM-Reference-Format}
%
%
%%% Appendix
%\appendix
%\section{Appendix}


\end{document}
